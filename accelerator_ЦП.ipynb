{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SergeyKamenshchikov/CRIP_recognition/blob/main/accelerator_%D0%A6%D0%9F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B59bq5skxkBS"
      },
      "source": [
        "##### Install libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vUhABMW518AA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6825e8b-3a6d-42b8-b1dc-b83427d73ca5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pdfplumber\n",
            "  Downloading pdfplumber-0.11.7-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdfminer.six==20250506 (from pdfplumber)\n",
            "  Downloading pdfminer_six-20250506-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: Pillow>=9.1 in /usr/local/lib/python3.12/dist-packages (from pdfplumber) (11.3.0)\n",
            "Collecting pypdfium2>=4.18.0 (from pdfplumber)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (3.4.3)\n",
            "Requirement already satisfied: cryptography>=36.0.0 in /usr/local/lib/python3.12/dist-packages (from pdfminer.six==20250506->pdfplumber) (43.0.3)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.0.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20250506->pdfplumber) (2.23)\n",
            "Downloading pdfplumber-0.11.7-py3-none-any.whl (60 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pdfminer_six-20250506-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m101.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m76.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdfium2, pdfminer.six, pdfplumber\n",
            "Successfully installed pdfminer.six-20250506 pdfplumber-0.11.7 pypdfium2-4.30.0\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.6/389.6 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pdf2image\n",
            "  Downloading pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from pdf2image) (11.3.0)\n",
            "Downloading pdf2image-1.17.0-py3-none-any.whl (11 kB)\n",
            "Installing collected packages: pdf2image\n",
            "Successfully installed pdf2image-1.17.0\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  poppler-utils\n",
            "0 upgraded, 1 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 186 kB of archives.\n",
            "After this operation, 697 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.10 [186 kB]\n",
            "Fetched 186 kB in 1s (191 kB/s)\n",
            "Selecting previously unselected package poppler-utils.\n",
            "(Reading database ... 126441 files and directories currently installed.)\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.10_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.10) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.8.0+cu126)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.23.0+cu126)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.12/dist-packages (from easyocr) (4.12.0.88)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from easyocr) (1.16.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from easyocr) (11.3.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr) (0.25.2)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr) (2.1.1)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.19.1)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch->easyocr) (3.4.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (2025.9.9)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (25.0)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->easyocr) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->easyocr) (3.0.2)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.13.0 pyclipper-1.3.0.post6 python-bidi-0.6.6\n",
            "Get:1 https://cli.github.com/packages stable InRelease [3,917 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [2,045 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Get:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:10 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [3,371 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Hit:13 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:14 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,805 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,690 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,274 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,577 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [9,305 kB]\n",
            "Fetched 24.5 MB in 4s (5,546 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3 pandoc-data\n",
            "Suggested packages:\n",
            "  texlive-latex-recommended texlive-xetex texlive-luatex pandoc-citeproc\n",
            "  texlive-latex-extra context wkhtmltopdf librsvg2-bin groff ghc nodejs php\n",
            "  python ruby libjs-mathjax libjs-katex citation-style-language-styles\n",
            "The following NEW packages will be installed:\n",
            "  libcmark-gfm-extensions0.29.0.gfm.3 libcmark-gfm0.29.0.gfm.3 pandoc\n",
            "  pandoc-data\n",
            "0 upgraded, 4 newly installed, 0 to remove and 46 not upgraded.\n",
            "Need to get 20.6 MB of archives.\n",
            "After this operation, 156 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [115 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 libcmark-gfm-extensions0.29.0.gfm.3 amd64 0.29.0.gfm.3-3 [25.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc-data all 2.9.2.1-3ubuntu2 [81.8 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/universe amd64 pandoc amd64 2.9.2.1-3ubuntu2 [20.3 MB]\n",
            "Fetched 20.6 MB in 3s (8,081 kB/s)\n",
            "Selecting previously unselected package libcmark-gfm0.29.0.gfm.3:amd64.\n",
            "(Reading database ... 126471 files and directories currently installed.)\n",
            "Preparing to unpack .../libcmark-gfm0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package libcmark-gfm-extensions0.29.0.gfm.3:amd64.\n",
            "Preparing to unpack .../libcmark-gfm-extensions0.29.0.gfm.3_0.29.0.gfm.3-3_amd64.deb ...\n",
            "Unpacking libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Selecting previously unselected package pandoc-data.\n",
            "Preparing to unpack .../pandoc-data_2.9.2.1-3ubuntu2_all.deb ...\n",
            "Unpacking pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Selecting previously unselected package pandoc.\n",
            "Preparing to unpack .../pandoc_2.9.2.1-3ubuntu2_amd64.deb ...\n",
            "Unpacking pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Setting up libcmark-gfm0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up libcmark-gfm-extensions0.29.0.gfm.3:amd64 (0.29.0.gfm.3-3) ...\n",
            "Setting up pandoc-data (2.9.2.1-3ubuntu2) ...\n",
            "Setting up pandoc (2.9.2.1-3ubuntu2) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.12/dist-packages (0.9.0)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (11.3.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m29.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.9 python-pptx-1.0.2\n",
            "Collecting pypandoc\n",
            "  Downloading pypandoc-1.15-py3-none-any.whl.metadata (16 kB)\n",
            "Downloading pypandoc-1.15-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: pypandoc\n",
            "Successfully installed pypandoc-1.15\n"
          ]
        }
      ],
      "source": [
        "!pip3 install pdfplumber\n",
        "!pip3 install openai==1.55.3 -q\n",
        "\n",
        "!pip3 install pdf2image\n",
        "!apt-get install poppler-utils\n",
        "!pip3 install easyocr\n",
        "\n",
        "!apt-get update && apt-get install -y pandoc\n",
        "!pip3 install python-pptx pandas tabulate\n",
        "!pip3 install pypandoc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9PgXsB5kxpkF"
      },
      "source": [
        "##### Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sWflTIct2Ml9",
        "outputId": "db8f2fd7-d0b7-4041-bb9a-03c43c089b53"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "from PIL import Image\n",
        "import os, time, json\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from tqdm import tqdm\n",
        "from pptx import Presentation\n",
        "\n",
        "from google.colab import drive\n",
        "from google.colab import output\n",
        "from google.colab import files\n",
        "\n",
        "from joblib import Parallel, delayed\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "from IPython.display import display\n",
        "\n",
        "import nltk, re\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "from pdf2image import convert_from_path\n",
        "import easyocr, pdfplumber\n",
        "\n",
        "import warnings, logging\n",
        "\n",
        "import threading, queue\n",
        "from collections import namedtuple\n",
        "\n",
        "import base64\n",
        "import tempfile\n",
        "import pypandoc\n",
        "\n",
        "from PIL import Image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibVtdNydwZJj"
      },
      "source": [
        "##### Ignore warnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ogrTAt26wdIR"
      },
      "outputs": [],
      "source": [
        "warnings.filterwarnings(\"ignore\")\n",
        "logging.getLogger(\"pdfminer\").setLevel(logging.ERROR)\n",
        "Image.MAX_IMAGE_PIXELS = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uz890Tzywq7C"
      },
      "source": [
        "##### Keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gl5TIOlawu4I"
      },
      "outputs": [],
      "source": [
        "os.environ[\"OPENAI_API_KEY\"] = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILekkyFAQotF"
      },
      "source": [
        "##### UDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TMbxXNuaQrMh"
      },
      "outputs": [],
      "source": [
        "# docx converters\n",
        "def docx_to_plain_with_simple_tables(path: str) -> str:\n",
        "    return pypandoc.convert_file(path, to=\"plain+simple_tables\", format=\"docx\")\n",
        "\n",
        "def pptx_to_markdown(pptx_file):\n",
        "    prs = Presentation(pptx_file)\n",
        "    md_content = []\n",
        "\n",
        "    for i, slide in enumerate(prs.slides, 1):\n",
        "        md_content.append(f\"## Slide {i}\\n\")\n",
        "\n",
        "        for shape in slide.shapes:\n",
        "            if shape.has_text_frame:\n",
        "                for paragraph in shape.text_frame.paragraphs:\n",
        "                    if paragraph.text.strip():\n",
        "                        md_content.append(paragraph.text + \"\\n\")\n",
        "\n",
        "            elif shape.has_table:\n",
        "                table = shape.table\n",
        "                table_data = []\n",
        "                for row in table.rows:\n",
        "                    row_data = [cell.text.strip() for cell in row.cells]\n",
        "                    table_data.append(row_data)\n",
        "\n",
        "                if table_data:\n",
        "                    df = pd.DataFrame(table_data[1:], columns=table_data[0])\n",
        "                    md_content.append(df.to_markdown(index=False) + \"\\n\\n\")\n",
        "\n",
        "        md_content.append(\"---\\n\\n\")\n",
        "\n",
        "    return ''.join(md_content)\n",
        "# docx converters\n",
        "\n",
        "# field extraction\n",
        "def extract_field(text, prompt, counter=0, model=\"o3\") -> dict:\n",
        "\n",
        "    client = OpenAI()\n",
        "\n",
        "    system_prompt = (\"Ты эксперт по технологическим стартапам и смотришь презентацию стартапа для Банка\")\n",
        "\n",
        "    schema = {\"name\": \"startup_analysis\", \"schema\": {\"type\": \"object\", \"properties\": {\"company_name\": {\"type\": \"string\"}, \"tech_product\": {\"type\": \"string\"},\\\n",
        "                \"tasks\": {\"type\": \"string\"}, \"company_projects\": {\"type\": \"string\"}, \"target_audience\": {\"type\": \"string\"},\n",
        "                \"target_audience_companies\": {\"type\": \"string\"}, \"target_audience_people\": {\"type\": \"string\"}, \"bank_profit\": {\"type\": \"string\"}, \"metrics\": {\"type\": \"string\"},\n",
        "                \"achievments\": {\"type\": \"string\"}},\n",
        "\n",
        "            \"required\": [\"company_name\", \"tech_product\", \"tasks\", \"company_projects\", \"target_audience\", \"target_audience_companies\",\\\n",
        "                         \"target_audience_people\", \"bank_profit\", \"metrics\", \"achievments\"], \"additionalProperties\": False}, \"strict\": True}\n",
        "\n",
        "    messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": f'task: {prompt} : \"text: {text}\"'}]\n",
        "    response = client.chat.completions.create(model=model, messages=messages, response_format={\"type\": \"json_schema\", \"json_schema\": schema})\n",
        "\n",
        "    return json.loads(response.choices[0].message.content)\n",
        "\n",
        "def return_fields(doc_txt):\n",
        "\n",
        "    result = extract_field(doc_txt, '''извлеки отсюда информацию в JSON формате:\n",
        "        1. company_name: название компании - если нет, выведи только одно слово 'НЕТ'\n",
        "        2. tech_product: технологический продукт компании - если нет, выведи только одно слово 'НЕТ'\n",
        "        3. tasks: Задачи, которые решаются с помощью технологии или продукта без упоминания проекта, продукта и организации - если нет, выведи только одно слово 'НЕТ'\n",
        "        4. company_projects: реализованные именно компанией проекты (с указанием организации, где был реализован проект) - если нет, выведи только одно слово 'НЕТ'\n",
        "        5. target_audience: целевая аудитория продукта среди подразделений Банка - если нет, выведи только одно слово 'НЕТ'\n",
        "        6. target_audience_companies: целевая аудитория продукта среди юридических лиц - если нет, выведи только одно слово 'НЕТ'\n",
        "        7. target_audience_people: целевая аудитория продукта среди физических лиц - если нет, выведи только одно слово 'НЕТ'\n",
        "        8. bank_profit: предложение, преимущества или выгода для Банка - если нет, выведи только одно слово 'НЕТ'\n",
        "        9. metrics: численные бизнес метрики, которые будут достигнуты именно для клиента, а не самой организацией (с цифрами, если они есть в виде чисел, а не слов)\\\n",
        "      - если нет, выведи только одно слово 'НЕТ'\n",
        "        10. achievments: достижения и награды проекта или продукта (не человека), полученные от других организаций - если нет, выведи только одно слово 'НЕТ''')\n",
        "\n",
        "    return result\n",
        "#/field extraction\n",
        "\n",
        "# parallel computations\n",
        "def parallel_extraction(texts, max_workers: int = 10):\n",
        "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
        "        results = list(tqdm(executor.map(lambda x: return_fields(x), texts), total=len(texts)))\n",
        "    return results\n",
        "#/parallel computations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "raVzrK7J0WJm"
      },
      "source": [
        "##### Load decks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MTxgh_-s0Ydh",
        "outputId": "48afcbab-90c5-464d-ceae-61c7b2ce5c14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')\n",
        "!cp -r '/content/drive/My Drive/Pitchdecks' '/content/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mDahnDV2Erp"
      },
      "source": [
        "##### Extract fields"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "r_Sks6AC2L0M",
        "outputId": "94d43334-37f3-410a-da42-89bfd0fc4c80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n",
            "100%|██████████| 1/1 [00:00<00:00, 15.00it/s]\n",
            "  0%|          | 0/2 [00:00<?, ?it/s]WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progress: |██████████████████████████████████████████████████| 100.1% Complete"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [01:38<00:00, 49.35s/it]\n",
            "100%|██████████| 3/3 [00:27<00:00,  9.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1min 34s, sys: 7.71 s, total: 1min 42s\n",
            "Wall time: 3min 28s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "folder_path = '/content/Pitchdecks'\n",
        "df_fields, file_texts, adresses = [], [], []\n",
        "\n",
        "### Extract .docx files\n",
        "docx_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.docx')])\n",
        "\n",
        "for docx_file in tqdm(docx_files):\n",
        "\n",
        "    pptx_path = os.path.join(folder_path, docx_file)\n",
        "    adresses.append(pptx_path.replace('/content/Питчи/', ''))\n",
        "\n",
        "    file_texts.append(docx_to_plain_with_simple_tables(pptx_path))\n",
        "###/Extract .docx files\n",
        "\n",
        "### Extract .pptx files\n",
        "pptx_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.pptx')])\n",
        "\n",
        "for pptx_file in tqdm(pptx_files):\n",
        "\n",
        "    pptx_path = os.path.join(folder_path, pptx_file)\n",
        "    adresses.append(pptx_path.replace('/content/Питчи/', ''))\n",
        "\n",
        "    file_texts.append(pptx_to_markdown(pptx_path))\n",
        "###/Extract .pptx files\n",
        "\n",
        "### Extract .pdf files\n",
        "pdf_files = sorted([f for f in os.listdir(folder_path) if f.endswith('.pdf')])\n",
        "\n",
        "for pdf_file in tqdm(pdf_files):\n",
        "\n",
        "    pdf_path = os.path.join(folder_path, pdf_file)\n",
        "    adresses.append(pdf_path.replace('/content/Питчи/', ''))\n",
        "\n",
        "    ### Image recognition ###\n",
        "    pdf_images = convert_from_path(pdf_path, thread_count=10)\n",
        "\n",
        "    for idx, image in enumerate(pdf_images):\n",
        "      image.save(f'pdf_page_{idx + 1}.png', 'PNG')\n",
        "\n",
        "    image_dir = '/content/'\n",
        "    reader = easyocr.Reader(['ru', 'en'], gpu = True)\n",
        "\n",
        "    text_results = []\n",
        "\n",
        "    for filename in sorted(os.listdir(image_dir)):\n",
        "\n",
        "        if filename.lower().endswith('.png'):\n",
        "\n",
        "          try:\n",
        "            img_path = os.path.join(image_dir, filename)\n",
        "            result = reader.readtext(img_path, detail=0, paragraph=True)\n",
        "            text_results.extend(result)\n",
        "          except:\n",
        "            print(\"Can't recognize the image\")\n",
        "\n",
        "    img_text = '\\n'.join(text_results)\n",
        "    !rm /content/*.png\n",
        "    ###/Image recognition ###\n",
        "\n",
        "    # Extract text with PDF reader\n",
        "    with pdfplumber.open(pdf_path) as pdf:\n",
        "      text = ''\n",
        "      for page in pdf.pages:\n",
        "          text += page.extract_text() + '\\n'\n",
        "\n",
        "    doc_txt = text.replace('02.12.2024, 22:35 Документ от auto-coder.net', '')\n",
        "    #/Extract text with PDF reader\n",
        "\n",
        "    file_texts.append(img_text + '|Краткое содержание текста: ' + doc_txt)\n",
        "\n",
        "df_fields = list(parallel_extraction(file_texts))\n",
        "df_fields = [[i for i in sublist if i != ''] for sublist in df_fields]\n",
        "\n",
        "output.eval_js('new Audio(\"https://upload.wikimedia.org/wikipedia/commons/0/05/Beep-09.ogg\").play()')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJHhCkpP3OOs"
      },
      "source": [
        "##### Create dataframe:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tu2xqa-Y3RBF",
        "outputId": "9d963170-8cec-4f85-e711-d0bf41c063f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------------------+-------------------------------+--------------+-----------------------------+-------------------------+----------------------------+----------------------------------------+---------------------------------------+-------------------+-----------+--------------+\n",
            "| Название компании   | Файл                          | Продукт      | Решаемые продуктом задачи   | Реализованные проекты   | Целевая аудитория - Банк   | Целевая аудитория - юридические лица   | Целевая аудитория - физические лица   | Оффер для Банка   | Метрики   | Достижения   |\n",
            "+=====================+===============================+==============+=============================+=========================+============================+========================================+=======================================+===================+===========+==============+\n",
            "| Company_name        | 42_PC-DEPOT_презентация.pptx  | Tech_product | Tasks                       | Company_projects        | Target_audience            | Target_audience_companies              | Target_audience_people                | Bank_profit       | Metrics   | Achievments  |\n",
            "+---------------------+-------------------------------+--------------+-----------------------------+-------------------------+----------------------------+----------------------------------------+---------------------------------------+-------------------+-----------+--------------+\n",
            "| Company_name        | 40_Mondiara_презентация.pdf   | Tech_product | Tasks                       | Company_projects        | Target_audience            | Target_audience_companies              | Target_audience_people                | Bank_profit       | Metrics   | Achievments  |\n",
            "+---------------------+-------------------------------+--------------+-----------------------------+-------------------------+----------------------------+----------------------------------------+---------------------------------------+-------------------+-----------+--------------+\n",
            "| Company_name        | 41_aIDeepFake_презентация.pdf | Tech_product | Tasks                       | Company_projects        | Target_audience            | Target_audience_companies              | Target_audience_people                | Bank_profit       | Metrics   | Achievments  |\n",
            "+---------------------+-------------------------------+--------------+-----------------------------+-------------------------+----------------------------+----------------------------------------+---------------------------------------+-------------------+-----------+--------------+\n"
          ]
        }
      ],
      "source": [
        "df = pd.DataFrame(df_fields, columns=['Название компании', 'Продукт', 'Решаемые продуктом задачи', 'Реализованные проекты', 'Целевая аудитория - Банк',\\\n",
        "                                      'Целевая аудитория - юридические лица', 'Целевая аудитория - физические лица', 'Оффер для Банка', 'Метрики', 'Достижения'])\n",
        "\n",
        "df['Файл'] = adresses\n",
        "df['Файл'] = df['Файл'].str.split('/').str[-1]\n",
        "\n",
        "cols = df.columns.tolist()\n",
        "cols.insert(1, cols.pop(cols.index('Файл')))\n",
        "df = df[cols]\n",
        "\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == 'object':\n",
        "        df[col] = df[col].apply(lambda x: x[0].upper() + x[1:] if isinstance(x, str) and x and not x[0].isupper() else x)\n",
        "\n",
        "print(df.to_markdown(index=False, tablefmt=\"grid\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2YnQ3t85jWm"
      },
      "source": [
        "##### Save to xlsx:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iWjURaeI5mPn",
        "outputId": "62e72081-d74e-4da3-ed38-09e7383d0656"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_9955449e-bf64-44e7-ba97-dfda5495ed99\", \"pitches - \\u0426\\u0420\\u0418\\u041f.xlsx\", 29041)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df.to_excel('pitches - ЦРИП.xlsx', index=False)\n",
        "files.download('pitches - ЦРИП.xlsx')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "B59bq5skxkBS",
        "9PgXsB5kxpkF",
        "ibVtdNydwZJj",
        "uz890Tzywq7C",
        "ILekkyFAQotF"
      ],
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}